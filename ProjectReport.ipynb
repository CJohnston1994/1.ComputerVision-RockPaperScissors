{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV-RPS REPORT\n",
    "This is a report done in parellel to the computer vision project using a jupyter notebook in VSCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1\n",
    "Goal: Create and download a model from teachable machine. and document the experience.\n",
    "\n",
    "# Task 1 - Create an image project model with 4 different classes: Rock, Paper, Scissors and Nothing\n",
    "Creating the model was a little bit of a challenge for something so seemingly simple. I tested different advanced settings in the beginning and ended up with 2 different models that were both having trouble differentiating between the Paper and scissors classes. Finally I settled on a model with fewer images, but that was giving more certain results. This had around 70-120 images per class. I was debaiting having more images and incorperating different hand shapes per class, e.g paper with fingers closed vs spread, but this seemed unnceessarily complicated. As a base model this will be perfect, but I would Like to come back later and create a more refined model  that does include these features\n",
    "\n",
    "# Task 2 - Download the model\n",
    "Downloading the model was rather easy, though before finding the video I was unsure which of the tensorflow options to use, Thankfully after looking over the next milestone it would have been easy to realise that keras was the correct option.\n",
    "\n",
    "# Task 3 - Begin documenting your experiences\n",
    "Reporting consistently is not one of my strong suits, But this is my attempt. I may come across as too formal or not formal enough at times but It'll do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "Goal: create a virtual environment, instrall the dependencies and run the provided code\n",
    "\n",
    "# Task 1 - Create a new virtual environment:\n",
    "This task was rather easy though I made the mistake of acting before I had read the task and installed the dependencies before I created the environment. I've never worked with virtual environments in such a way before so I was unsure of what to expect, but it makes basic sense without looking too deep into it for now. It is very helpful for instancing environment to run codde with specific demendencies and allows the prevention of possible clashes or issues with other packages, or allows the use of older packages than are installed or newer packages to test if updating is viable.\n",
    "\n",
    "# Task 2 - Run the moddel in your local machine.\n",
    "This task gave me a few issues, These were solved after 2-3 ddays googling. I was mainly having issues with the jupyter notebook failing to start the python kernel. The solution was to uninstall all jupyrter related packages and let VSCode install them automatically after running the code in the notebook. The solution was found here:\n",
    "https://stackoverflow.com/questions/71003266/kernel-failed-to-start-using-conda-environment-with-jupyter-in-visual-studio-cod\n",
    "\n",
    "I ran the command line:\n",
    "python3 -m pip uninstall -y jupyter jupyter_core jupyter-client jupyter-console jupyterlab_pygments notebook qtconsole nbconvert nbformat jupyterlab-widgets nbclient ipykernel ipynb\n",
    "\n",
    "then reinstalled through VSCode and everything worked fine.\n",
    "\n",
    "# Task 3 - Get famaliar with the code:\n",
    "There is alot of the code that I have never seen before and this is my first time working on something more basic than python syntax, so I may need to do a little more learning.\n",
    "From what I have gathered, the first 5 lienes are just initializing the variables, the while loop is then entered and the camera feed is normalized to fit the dataset. The prediction is then printed to the output in 4 different values corresponding to the classes of the training set: Rock, Paper, Scissors and None. finally the program does this until it is cloeed with the 'q' key, triggering the if statement which leads to a break. or by terminating the program in the IDE. once the while loop is exited via the break the image capture is released and the window is closed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model('keras_model.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "    image_np = np.array(resized_frame)\n",
    "    normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "    data[0] = normalized_image\n",
    "    prediction = model.predict(data)\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Press q to close the window\n",
    "    print(prediction[[0]])\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "            \n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 3\n",
    "Milestone 3 covers the logic necessary for the game of rock paper scissors\n",
    "\n",
    "# Task 1 - Store the user's and the computer's choices\n",
    "Having been a while since I used python, This took a few attempts. but through the power of Google and determination I was able to get the inputs, Then after rereading the task I split the code into the 2 different classes\n",
    "\n",
    "# Rask 2 - Figure out who won\n",
    "I was almost interested to try and find a way to match two lists to create a smaller if-else chain, using the rock paper scissors of options and adding a paper scissors rock list and matching them. realising that a string was returned from the earlier task I added \n",
    "\n",
    "# Task 3 - Create a function to simulatre the game\n",
    "Simply wrapped my function calls in a function called play() and ran that function after.\n",
    "\n",
    "# Task 4 - Update the documentation.\n",
    "This task took an hour or so but was very fun and gave me ideas that I could use to come back at a later date and see how I could do this differently with more knowledge and experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 4 - Use the Camera to play Rock-Paper-Scissors\n",
    "\n",
    "# Task 1 - Putting it all together\n",
    "I started by importing the play function form the manual_rps python file created in Milestone 3.\n",
    "I then worked on obstracting the value from the modle to get the users choice. This has lead me to needing to create a better keras model as the prediction is not very acurate.\n",
    "for the next model I will be bringing my hand closer to the camera to allow for less background visibility, this will hopefully lower the effect of light and background variance and allow a more accurate predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model('keras_model.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "def print_choice(frame, model_output):\n",
    "    options = ['Rock', 'Paper', 'Scissors','None']\n",
    "    output_reading = np.argmax(model_output[0])\n",
    "    text = f\"Player is choosing {options[output_reading]}\"\n",
    "    img = cv2.putText(frame, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (147, 101, 26), 3, cv2.LINE_AA)\n",
    "\n",
    "def normalize_image():\n",
    "    resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "    image_np = np.array(resized_frame)\n",
    "    normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "    return normalize_image\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    data[0] = normalize_image\n",
    "    prediction = model.predict(data)\n",
    "    print_choice(frame, prediction)\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Press q to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "            \n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model('keras_model.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "options = ['Rock', 'Paper', 'Scissors','None']\n",
    "\n",
    "def print_choice(frame, model_output):\n",
    "    output_reading = np.argmax(model_output[0])\n",
    "    text = f\"Player is showing {options[output_reading]}!\"\n",
    "    img = cv2.putText(frame, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (147, 101, 26), 3, cv2.LINE_AA)\n",
    "\n",
    "def set_player_choice(model_output):\n",
    "    player_choice = options[model_output]\n",
    "    return player_choice\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "    image_np = np.array(resized_frame)\n",
    "    normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "    data[0] = normalized_image\n",
    "    prediction = model.predict(data)\n",
    "    print_choice(frame, prediction)\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Press q to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "            \n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_4415/3316352904.py\", line 5, in <cell line: 5>\n",
      "    import manual_rps\n",
      "  File \"/home/clark/Desktop/AICORE/Code/1.-ComputerVision---RockPaperScissors/manual_rps.py\", line 39, in <module>\n",
      "    play()\n",
      "TypeError: play() missing 1 required positional argument: 'prediction'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/clark/miniconda3/envs/rps-env/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import camera_rps\n",
    "import manual_rps\n",
    "model = load_model('keras_model.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "def set_player_choice(model_output):\n",
    "    player_choice = options[model_output]\n",
    "    return player_choice\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "    image_np = np.array(resized_frame)\n",
    "    normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "    data[0] = normalized_image\n",
    "    prediction = model.predict(data)\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Press q to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        manual_rps.play(camera_rps.get_prediction())\n",
    "\n",
    "            \n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8a06c1630a15f5b4f9162d9df54978e0aacf3b302c009093c1f53a5b592491e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
